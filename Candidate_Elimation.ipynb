{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSZBaOj/xEN8m44i5iP6R7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naman30903/Machine_learning/blob/main/Candidate_Elimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftP-s9wQqiE4",
        "outputId": "19124dfc-13ef-47d8-af0d-200baa27f0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET:\n",
            "     Sky AirTemp Humidity    Wind Water Forecast EnjoySport\n",
            "0  Sunny    Warm   Normal  Strong  Warm     Same        Yes\n",
            "1  Sunny    Warm     High  Strong  Warm     Same        Yes\n",
            "2  Rainy    Cold     High  Strong  Warm   Change         No\n",
            "3  Sunny    Warm     High  Strong  Cool   Change        Yes\n",
            "\n",
            "============================================================\n",
            "\n",
            "RUNNING CANDIDATE ELIMINATION ALGORITHM...\n",
            "============================================================\n",
            "\n",
            "Initial Specific Hypothesis (S): ['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same']\n",
            "Initial General Hypothesis (G): [['?', '?', '?', '?', '?', '?']]\n",
            "--------------------------------------------------\n",
            "Training Example 1: ['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same'], Class: Yes\n",
            "Current S: ['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same']\n",
            "Current G: [['?', '?', '?', '?', '?', '?']]\n",
            "--------------------------------------------------\n",
            "Training Example 2: ['Sunny' 'Warm' 'High' 'Strong' 'Warm' 'Same'], Class: Yes\n",
            "Current S: ['Sunny' 'Warm' '?' 'Strong' 'Warm' 'Same']\n",
            "Current G: [['?', '?', '?', '?', '?', '?']]\n",
            "--------------------------------------------------\n",
            "Training Example 3: ['Rainy' 'Cold' 'High' 'Strong' 'Warm' 'Change'], Class: No\n",
            "Current S: ['Sunny' 'Warm' '?' 'Strong' 'Warm' 'Same']\n",
            "Current G: [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
            "--------------------------------------------------\n",
            "Training Example 4: ['Sunny' 'Warm' 'High' 'Strong' 'Cool' 'Change'], Class: Yes\n",
            "Current S: ['Sunny' 'Warm' '?' 'Strong' '?' '?']\n",
            "Current G: [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
            "--------------------------------------------------\n",
            "\n",
            "FINAL RESULTS:\n",
            "============================================================\n",
            "\n",
            "Final Specific Hypothesis (S):\n",
            "This is the most specific hypothesis that fits all positive examples.\n",
            "  Sky: Sunny\n",
            "  AirTemp: Warm\n",
            "  Humidity: ?\n",
            "  Wind: Strong\n",
            "  Water: ?\n",
            "  Forecast: ?\n",
            "\n",
            "Final General Hypothesis Boundary (G):\n",
            "These are the most general hypotheses that don't cover any negative examples.\n",
            "  Hypothesis 1:\n",
            "    Sky: Sunny\n",
            "    AirTemp: ?\n",
            "    Humidity: ?\n",
            "    Wind: ?\n",
            "    Water: ?\n",
            "    Forecast: ?\n",
            "  Hypothesis 2:\n",
            "    Sky: ?\n",
            "    AirTemp: Warm\n",
            "    Humidity: ?\n",
            "    Wind: ?\n",
            "    Water: ?\n",
            "    Forecast: ?\n",
            "  Hypothesis 3:\n",
            "    Sky: ?\n",
            "    AirTemp: ?\n",
            "    Humidity: ?\n",
            "    Wind: ?\n",
            "    Water: ?\n",
            "    Forecast: Same\n",
            "\n",
            "EXPLANATION:\n",
            "============================================================\n",
            "The Version Space is the set of all hypotheses that lie between S and G.\n",
            "Any hypothesis in this space will correctly classify the training examples.\n",
            "- If a feature has a specific value in S, it must have that value for a positive example.\n",
            "- The G boundary ensures we don't include hypotheses that cover negative examples.\n",
            "- A '?' represents a 'don't care' value that can match any attribute value.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def candidate_elimination(df):\n",
        "    # Extract features and target from dataframe\n",
        "    features = df.iloc[:, :-1].values\n",
        "    target = df.iloc[:, -1].values\n",
        "    feature_names = df.columns[:-1]\n",
        "\n",
        "    # Number of attributes (columns excluding the target)\n",
        "    n_attributes = features.shape[1]\n",
        "\n",
        "    # Step 1: Initialize the specific hypothesis with the first positive example\n",
        "    specific_h = None\n",
        "    for i in range(len(features)):\n",
        "        if target[i] == 'Yes':\n",
        "            specific_h = features[i].copy()\n",
        "            break\n",
        "\n",
        "    if specific_h is None:\n",
        "        return \"No positive examples found\", []\n",
        "\n",
        "    # Initialize G (general boundary) with the most general hypotheses\n",
        "    # Initially, all attributes are '?' (wildcard that matches any value)\n",
        "    general_h = [['?' for _ in range(n_attributes)]]\n",
        "\n",
        "    # Print initial hypotheses\n",
        "    print(\"Initial Specific Hypothesis (S):\", specific_h)\n",
        "    print(\"Initial General Hypothesis (G):\", general_h)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Step 2: Process each training example to refine S and G\n",
        "    for i in range(len(features)):\n",
        "        current_example = features[i]\n",
        "        current_target = target[i]\n",
        "\n",
        "        print(f\"Training Example {i+1}: {current_example}, Class: {current_target}\")\n",
        "\n",
        "        # Case 1: Positive Example - Generalize S if needed\n",
        "        if current_target == 'Yes':\n",
        "            # Update specific hypothesis: If attribute values don't match, replace with '?'\n",
        "            for j in range(n_attributes):\n",
        "                if specific_h[j] != current_example[j]:\n",
        "                    specific_h[j] = '?'\n",
        "\n",
        "        # Case 2: Negative Example - Specialize G if needed\n",
        "        else:  # current_target == 'No'\n",
        "            # We need to make G more specific to exclude this negative example\n",
        "            general_h_new = []\n",
        "\n",
        "            for g in general_h:\n",
        "                # Check if this general hypothesis covers the negative example\n",
        "                if all(g[j] == '?' or g[j] == current_example[j] for j in range(n_attributes)):\n",
        "                    # This general hypothesis incorrectly covers the negative example\n",
        "                    # For each attribute where specific_h differs from the negative example\n",
        "                    for j in range(n_attributes):\n",
        "                        if specific_h[j] != '?' and specific_h[j] != current_example[j]:\n",
        "                            # Create a new general hypothesis that's more specific\n",
        "                            g_new = g.copy()\n",
        "                            g_new[j] = specific_h[j]\n",
        "\n",
        "                            # Add to new general hypotheses if it's consistent with specific_h\n",
        "                            # and not already in the list\n",
        "                            if g_new not in general_h_new:\n",
        "                                is_consistent = True\n",
        "                                for k in range(n_attributes):\n",
        "                                    if specific_h[k] != '?' and g_new[k] != '?' and specific_h[k] != g_new[k]:\n",
        "                                        is_consistent = False\n",
        "                                        break\n",
        "                                if is_consistent:\n",
        "                                    general_h_new.append(g_new)\n",
        "                else:\n",
        "                    # This general hypothesis already excludes the negative example\n",
        "                    general_h_new.append(g)\n",
        "\n",
        "            # Update general hypothesis boundary\n",
        "            general_h = general_h_new\n",
        "\n",
        "        # After processing each example, print current state\n",
        "        print(\"Current S:\", specific_h)\n",
        "        print(\"Current G:\", general_h)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Convert numpy arrays to lists for better readability in final output\n",
        "    specific_h = specific_h.tolist() if hasattr(specific_h, 'tolist') else specific_h\n",
        "\n",
        "    # Create a more readable output with feature names\n",
        "    specific_h_dict = {feature_names[i]: specific_h[i] for i in range(n_attributes)}\n",
        "    general_h_dicts = [{feature_names[i]: g[i] for i in range(n_attributes)} for g in general_h]\n",
        "\n",
        "    return specific_h_dict, general_h_dicts\n",
        "\n",
        "def demonstrate_with_sample_data():\n",
        "    \"\"\"\n",
        "    Demonstrates the Candidate Elimination algorithm with a sample dataset.\n",
        "    \"\"\"\n",
        "    # Sample data: \"Enjoy Sport\" dataset - Whether to enjoy sport based on various conditions\n",
        "    sample_data = \"\"\"Sky,AirTemp,Humidity,Wind,Water,Forecast,EnjoySport\n",
        "Sunny,Warm,Normal,Strong,Warm,Same,Yes\n",
        "Sunny,Warm,High,Strong,Warm,Same,Yes\n",
        "Rainy,Cold,High,Strong,Warm,Change,No\n",
        "Sunny,Warm,High,Strong,Cool,Change,Yes\"\"\"\n",
        "\n",
        "    with open('enjoy_sport.csv', 'w') as f:\n",
        "        f.write(sample_data)\n",
        "\n",
        "    # Read and display the dataset\n",
        "    df = pd.read_csv('enjoy_sport.csv')\n",
        "    print(\"DATASET:\")\n",
        "    print(df)\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "    print(\"RUNNING CANDIDATE ELIMINATION ALGORITHM...\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # Run the algorithm\n",
        "    specific_h, general_h = candidate_elimination(df)\n",
        "\n",
        "    # Display final results\n",
        "    print(\"\\nFINAL RESULTS:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\nFinal Specific Hypothesis (S):\")\n",
        "    print(\"This is the most specific hypothesis that fits all positive examples.\")\n",
        "    for feature, value in specific_h.items():\n",
        "        print(f\"  {feature}: {value}\")\n",
        "\n",
        "    print(\"\\nFinal General Hypothesis Boundary (G):\")\n",
        "    print(\"These are the most general hypotheses that don't cover any negative examples.\")\n",
        "    for i, g in enumerate(general_h, 1):\n",
        "        print(f\"  Hypothesis {i}:\")\n",
        "        for feature, value in g.items():\n",
        "            print(f\"    {feature}: {value}\")\n",
        "\n",
        "    # Explanation of results\n",
        "    print(\"\\nEXPLANATION:\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"The Version Space is the set of all hypotheses that lie between S and G.\")\n",
        "    print(\"Any hypothesis in this space will correctly classify the training examples.\")\n",
        "    print(\"- If a feature has a specific value in S, it must have that value for a positive example.\")\n",
        "    print(\"- The G boundary ensures we don't include hypotheses that cover negative examples.\")\n",
        "    print(\"- A '?' represents a 'don't care' value that can match any attribute value.\")\n",
        "\n",
        "def demonstrate_with_user_data(file_path):\n",
        "    \"\"\"\n",
        "    Demonstrates the Candidate Elimination algorithm with user-provided data.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the CSV file containing training data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read and display the dataset\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(\"DATASET:\")\n",
        "        print(df)\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "        print(\"RUNNING CANDIDATE ELIMINATION ALGORITHM...\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # Run the algorithm\n",
        "        specific_h, general_h = candidate_elimination(df)\n",
        "\n",
        "        # Display final results\n",
        "        print(\"\\nFINAL RESULTS:\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"\\nFinal Specific Hypothesis (S):\")\n",
        "        print(\"This is the most specific hypothesis that fits all positive examples.\")\n",
        "        for feature, value in specific_h.items():\n",
        "            print(f\"  {feature}: {value}\")\n",
        "\n",
        "        print(\"\\nFinal General Hypothesis Boundary (G):\")\n",
        "        print(\"These are the most general hypotheses that don't cover any negative examples.\")\n",
        "        for i, g in enumerate(general_h, 1):\n",
        "            print(f\"  Hypothesis {i}:\")\n",
        "            for feature, value in g.items():\n",
        "                print(f\"    {feature}: {value}\")\n",
        "\n",
        "        # Explanation of results\n",
        "        print(\"\\nEXPLANATION:\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"The Version Space is the set of all hypotheses that lie between S and G.\")\n",
        "        print(\"Any hypothesis in this space will correctly classify the training examples.\")\n",
        "        print(\"- If a feature has a specific value in S, it must have that value for a positive example.\")\n",
        "        print(\"- The G boundary ensures we don't include hypotheses that cover negative examples.\")\n",
        "        print(\"- A '?' represents a 'don't care' value that can match any attribute value.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing the file: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # By default, run with sample data\n",
        "    demonstrate_with_sample_data()\n",
        "\n",
        "    # Uncomment below to run with your own data file\n",
        "    # demonstrate_with_user_data('your_data_file.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def candidate_elimination()"
      ],
      "metadata": {
        "id": "5uZ7AbSZsuF1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}